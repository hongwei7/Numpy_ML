{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "X=load_iris().data\n",
    "data_y=np.array(load_iris().target)\n",
    "data_y=(np.array([data_y==1]).astype('int'))\n",
    "data_y=data_y.T\n",
    "X.shape,data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "batch_size=150\n",
    "w1=tf.Variable(tf.random_normal([4,10],stddev=1))\n",
    "w2=tf.Variable(tf.random_normal([10,1],stddev=1))\n",
    "x=tf.placeholder(tf.float32,shape=(None,4),name='input')\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='output')\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "y=tf.sigmoid(y)\n",
    "#损失函数\n",
    "cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0))+(1-y_)*tf.log(tf.clip_by_value(1-y,1e-10,1.0)))\n",
    "learning_rate=0.01\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3380785   0.12703253 -0.17600143  0.6916246  -0.10818201  0.08308461\n",
      "  -0.8064169   0.18359107 -0.9290955   1.4400897 ]\n",
      " [-0.90060014  0.03533395  0.31326473  0.3806322   1.1579447  -0.26039416\n",
      "   0.17023562 -1.8513943  -0.3537099  -1.2137051 ]\n",
      " [-0.7311819   0.05421373 -0.75114435  0.13986067 -1.1871829   0.22808412\n",
      "   0.64451706 -0.8068346  -0.23510669  0.07916045]\n",
      " [-0.9511914   1.6421232   0.2733074   0.3646715  -0.8074277  -0.3616826\n",
      "   0.19119248  0.21762942  0.8961508   0.2785713 ]] [[-1.6048814 ]\n",
      " [-0.257353  ]\n",
      " [-0.41125956]\n",
      " [ 0.87505496]\n",
      " [ 0.25735465]\n",
      " [ 0.12725846]\n",
      " [ 0.95937645]\n",
      " [-1.3353715 ]\n",
      " [ 1.5978508 ]\n",
      " [-0.11791266]]\n",
      "0 1.2604538\n",
      "1000 0.5284755\n",
      "2000 0.5170676\n",
      "3000 0.51650316\n",
      "4000 0.516405\n",
      "5000 0.516371\n",
      "73.33333333333333\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    session.run(init_op)\n",
    "    print(session.run(w1),session.run(w2))\n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        session.run(train_step,feed_dict={x:X,y_:data_y})\n",
    "        if i%1000==0:\n",
    "            total_cross_entropy=session.run(cross_entropy,feed_dict={x:X,y_:data_y})\n",
    "            print(i,total_cross_entropy)\n",
    "    print(STEPS,session.run(cross_entropy,feed_dict={x:X,y_:data_y}))\n",
    "    print(((session.run(y,feed_dict={x:X,y_:data_y})>=0.5).astype('int')==data_y).sum()/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=150\n",
    "w1=tf.Variable(tf.random_normal([4,10],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([10,1],stddev=1,seed=1))\n",
    "x=tf.placeholder(tf.float32,shape=(None,4),name='input')\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='output')\n",
    "biases1=tf.Variable(tf.constant(0.1,shape=[batch_size,10]))\n",
    "a=tf.nn.relu(tf.matmul(x,w1)+biases1)\n",
    "y=tf.matmul(a,w2)\n",
    "y=tf.sigmoid(y)\n",
    "#损失函数\n",
    "cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0))+(1-y_)*tf.log(tf.clip_by_value(1-y,1e-10,1.0)))\n",
    "learning_rate=0.01\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.357681\n",
      "1000 0.30121854\n",
      "2000 0.18848717\n",
      "3000 0.13038073\n",
      "4000 0.09572974\n",
      "5000 0.07278483\n",
      "6000 0.056688514\n",
      "7000 0.045013215\n",
      "8000 0.03637862\n",
      "9000 0.02991189\n",
      "10000 0.025007816\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    session.run(init_op)\n",
    "    #print(session.run(w1),session.run(w2))\n",
    "    STEPS=10000\n",
    "    for i in range(STEPS):\n",
    "        session.run(train_step,feed_dict={x:X,y_:data_y})\n",
    "        if i%1000==0:\n",
    "            total_cross_entropy=session.run(cross_entropy,feed_dict={x:X,y_:data_y})\n",
    "            print(i,total_cross_entropy)\n",
    "    print(STEPS,session.run(cross_entropy,feed_dict={x:X,y_:data_y}))\n",
    "    print(((session.run(y,feed_dict={x:X,y_:data_y})>=0.5).astype('int')==data_y).sum()/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
